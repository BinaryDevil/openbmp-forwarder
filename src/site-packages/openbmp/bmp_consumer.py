# -*- coding: utf-8 -*-
"""OpenBMP forwarder

  Copyright (c) 2013-2015 Cisco Systems, Inc. and others.  All rights reserved.
  This program and the accompanying materials are made available under the
  terms of the Eclipse Public License v1.0 which accompanies this distribution,
  and is available at http://www.eclipse.org/legal/epl-v10.html

  .. moduleauthor:: Tim Evens <tievens@cisco.com>
"""
import multiprocessing
import socket
import kafka
import kafka.common
import time
import re
from datetime import datetime
from struct import pack


from openbmp.logger import init_mp_logger
from openbmp.parsed.headers import headers as parsed_headers
from openbmp.parsed.collector import collector
from openbmp.parsed.router import router
from openbmp.parsed.peer import peer
from openbmp.bmp import bmp_parse_bmphdr, bmp_parse_peerhdr

class BMPMessageObject(object):
    """ OpenBMP consumer message object which is used between internal queues """
    #: BMP Message
    BMP_MSG = None

    #: Collector Admin ID
    COLLECTOR_ADMIN_ID = ""

    #: Router IP
    ROUTER_IP = ""

    #: Router Name
    ROUTER_NAME = ""

    DEST_CONFIG_NAME = ""

    DEST_COLLECTOR_HOST = ""

    DEST_COLLECTOR_PORT = 0


class BMPConsumer(multiprocessing.Process):
    """ OpenBMP consumer for forwarding

        Consumes openbmp.parsed.collector, openbmp.parsed.router, and openbmp.bmp_raw
        message feeds from Kafka.  Collector and router messages are cached so the data can
        be used when forwarding. BMP messages
    """
    # Memory cache of collectors
    COLLECTORS = {}

    # Memory cache of routers
    ROUTERS = {}

    # Memory cache of peers
    PEERS = {}

    def __init__(self, cfg, forward_queue, log_queue):
        """ Constructor

            :param cfg:             Configuration dictionary
            :param forward_queue:   Output for BMP raw message forwarding
            :param log_queue:       Logging queue - sync logging
        """
        multiprocessing.Process.__init__(self)
        self._stop = multiprocessing.Event()

        self._cfg = cfg
        self._fwd_queue = forward_queue
        self._log_queue = log_queue
        self.LOG = None

    def run(self):
        """ Override """
        self.LOG = init_mp_logger("bmp_consumer", self._log_queue)

        # Enable to topics/feeds
        topics = ['openbmp.parsed.collector', 'openbmp.parsed.router', 'openbmp.parsed.peer', 'openbmp.bmp_raw']

        self.LOG.info("Running bmp_consumer")

        # wait for config to load
        while not self.stopped():
            if self._cfg and 'kafka' in self._cfg:
                break


        try:
            # connect and bind to topics
            self.LOG.info("Connecting to %s ... takes a minute to load offsets and topics, please wait" % self._cfg['kafka']['servers'])
            consumer = kafka.KafkaConsumer(*topics,
                                           bootstrap_servers=self._cfg['kafka']['servers'],
                                           client_id=self._cfg['kafka']['client_id'] + '-' + socket.gethostname(),
                                           group_id=self._cfg['kafka']['group_id'],
                                           enable_auto_commit=True,
                                           auto_commit_interval_ms=1000,
                                           auto_offset_reset='latest' if self._cfg['kafka']['offset_reset_largest'] else "smallest")

            self.LOG.info("Connected, now consuming")

            prev_ts = time.time()

            # Loop till stopped
            while not self.stopped():

                # Read messages
                for m in consumer:
                    if self.stopped():
                        break

                    self.process_msg(m)

        except kafka.common.KafkaUnavailableError as err:
            self.LOG.error("Kafka Error: %s" % str(err))

        except KeyboardInterrupt:
            pass

        self.LOG.info("consumer stopped")

    def stop(self):
        self._stop.set()

    def stopped(self):
        return self._stop.is_set()

    def process_msg(self, msg):
        """ Process the message

        :param msg:     Message consumed
        """
        (headers, data) = msg.value.split("\n\n", 1)

        hdr = parsed_headers()
        hdr.parse(headers)

        if msg.topic == 'openbmp.parsed.collector':
            self.process_collector_msg(hdr.getCollectorHashId(), data)

        if msg.topic == 'openbmp.parsed.router':
            self.process_router_msg(hdr.getCollectorHashId(), data)

        if msg.topic == 'openbmp.parsed.peer':
            self.process_peer_msg(hdr.getCollectorHashId(), data)

        elif msg.topic == 'openbmp.bmp_raw':
            self.process_bmp_raw_msg(hdr.getCollectorHashId(),
                                     hdr.getRouterHashId(), hdr.getRouterIp(), data)

    def process_collector_msg(self, c_hash, data):
        """ Process collector message and cache info for use later

            :param c_hash:      Collector Hash ID
            :param data:        Message data to be consumed (should not contain headers)
        """
        obj = collector()

        for row in data.split('\n'):
            if len(row):
                try:
                    obj.parse(row)

                    self.LOG.debug("collector: %s [%s]", obj.getAdminId(), obj.getAction())

                    if obj.getAction() in ('started', 'heartbeat', 'change'):

                        # Update collector hash/cache
                        if obj.getHashId() not in self.COLLECTORS:
                            self.COLLECTORS[obj.getHashId()] = {'admin_id': obj.getAdminId()}

                    else:
                        self.COLLECTORS.pop(obj.getHashId(), None)

                except:
                    pass

    def process_router_msg(self, c_hash, data):
        """ Process Router message

            :param c_hash:      Collector Hash ID
            :param data:        Message data to be consumed (should not contain headers)
        """
        obj = router()

        # Log messages
        for row in data.split('\n'):
            if len(row):
                try:
                    obj.parse(row)

                    self.LOG.debug("router: [%s] %s %s", obj.getAction(),
                                   obj.getName(), obj.getIpAddress())

                    if obj.getAction() in ('first', 'init'):
                        # Update the router hash/cache
                        if obj.getHashId() not in self.ROUTERS:
                            self.ROUTERS[obj.getHashId()] = {'ip': obj.getIpAddress(),
                                                             'name': obj.getName(),
                                                             'peer-list': []}
                    # else:
                    #     self.ROUTERS.pop(obj.getHashId(), None)

                except:
                    self.LOG.debug("router parse error");
                    pass

    def process_peer_msg(self, c_hash, data):
        """ Process Peer message

            :param c_hash:      Collector Hash ID
            :param data:        Message data to be consumed (should not contain headers)
        """
        obj = peer()

        # Log messages
        for row in data.split('\n'):
            if len(row):
                try:
                    obj.parse(row)

                    peer_key = obj.getRouterHashId() + '_' + obj.getRemoteBgpId() + '_' + str(obj.getPeerRd())

                    self.LOG.info("peer: [%s] %s %s", obj.getAction(),
                                   obj.getName(), obj.getLocalIp())

                    if obj.getAction() in ('up'):

                        asn_len = 2
                        if ('4 Octet ASN' in obj.getAdvCapabilities() and
                            '4 Octet ASN' in obj.getRecvCapabilities()):
                            asn_len = 4

                        # Update the peer hash/cache
                        # replace raw data with this one contains peer_name information
                        if obj.getAction() != 'down':
                            if peer_key in self.PEERS:
                                self.PEERS[peer_key] = dict((
                                                                {'peer_name': obj.getName(),
                                                                 'remote_ip': obj.getRemoteIp(),
                                                                 'remote_asn': obj.getRemoteAsn(),
                                                                 'local_ip': obj.getLocalIp(),
                                                                 'local_asn': obj.getLocalAsn(),
                                                                 'router_hash': obj.getRouterHashId(),
                                                                 'asn_len': asn_len,
                                                                 'rd': obj.getPeerRd()}.get(k, k), v) for (k, v) in
                                                            self.PEERS[peer_key].items())
                            if obj.getRouterHashId() in self.ROUTERS:
                                if peer_key not in self.ROUTERS[obj.getRouterHashId()]['peer-list']:
                                    self.ROUTERS[obj.getRouterHashId()]['peer-list'].append(peer_key)
                except:
                    self.LOG.debug("peer parse error")
                    pass

    def process_bmp_raw_msg(self, c_hash, r_hash, r_ip, data):
        """ Process BMP RAW message

        :param c_hash:      Collector Hash ID
        :param r_hash:      Router Hash ID
        :param r_ip:        Router IP address
        :param data:        Message data to be consumed (should not contain headers)
        """
        msg = BMPMessageObject()

        # Parse the BMP header
        bmp_hdrs = bmp_parse_bmphdr(data)

        # if bmp_hdrs['type'] != 'ROUTE_MON':
        print bmp_hdrs, self.PEERS, self.ROUTERS

        # Parse the BMP headers
        if bmp_hdrs['type'] in ('INIT', 'TERM'):
            # Send to ALL
            for dest_peer_group in self._cfg['dest_peer_groups']:
                if c_hash in self.COLLECTORS:
                    msg.COLLECTOR_ADMIN_ID = self.COLLECTORS[c_hash]['admin_id']

                if r_hash in self.ROUTERS:
                    msg.ROUTER_IP = self.ROUTERS[r_hash]['ip']
                    msg.ROUTER_NAME = self.ROUTERS[r_hash]['name']

                msg.DEST_CONFIG_NAME = dest_peer_group['name']
                msg.DEST_COLLECTOR_HOST = dest_peer_group['collector']['host']
                msg.DEST_COLLECTOR_PORT = dest_peer_group['collector']['port']
                msg.BMP_MSG = data
                self._fwd_queue.put(msg)

            # Generate Peer Down notifications to send to peer groups
            if bmp_hdrs['type'] == 'TERM':

                peer_list = []
                if r_hash in self.ROUTERS:
                    peer_list = self.ROUTERS[r_hash]['peer-list']
                else:
                    for key,peer in self.PEERS:
                        if peer['router_hash'] == r_hash:
                            peer_list.append(key)

                for peer_key in peer_list:
                    current_peer = self.PEERS[peer_key]
                    msg = BMPMessageObject()
                    hdr = {'version': 3,
                           'length': 6,
                           'type': 'PEER_DOWN',
                           'peer_type': current_peer['type'],
                           'peer_flags': current_peer['flags'],
                           'peer_dist_id': current_peer['rd'],
                           'peer_addr': current_peer['local_ip'],
                           'peer_asn': current_peer['local_asn'],
                           'peer_bgp_id': current_peer['bgp_id'],
                           'ts_secs': int(time.time()),
                           'ts_usecs': datetime.now().microsecond,
                           'reason': 5
                           }
                    msg.BMP_MSG = pack('>BIBBBQBBBBBBBBIBII',hdr)
                    if c_hash in self.COLLECTORS:
                        msg.COLLECTOR_ADMIN_ID = self.COLLECTORS[c_hash]['admin_id']

                    if r_hash in self.ROUTERS:
                        msg.ROUTER_IP = self.ROUTERS[r_hash]['ip']
                        msg.ROUTER_NAME = self.ROUTERS[r_hash]['name']

                    # Send to forward queue
                    self.LOG.debug('Doing match for generated peer down notification with PEER KEY: {}'.format(peer_key))

                    dest_peer_group = self.match_peer_group(current_peer)
                    if dest_peer_group is not None:
                        self.LOG.debug(
                            'PEER KEY: {} matched dest_peer_group {}'.format(peer_key, dest_peer_group['name']))
                        msg.DEST_CONFIG_NAME = dest_peer_group['name']
                        msg.DEST_COLLECTOR_HOST = dest_peer_group['collector']['host']
                        msg.DEST_COLLECTOR_PORT = dest_peer_group['collector']['port']
                        msg.BMP_MSG = data
                        self._fwd_queue.put(msg)
                    else:
                        self.LOG.error('PEER KEY: {} did not match any dest_peer_group!'.format(peer_key))
                    del self.PEERS[peer_key]
                del self.ROUTERS[r_hash]

        else:
            peer_hdr = bmp_parse_peerhdr(data[6:])

            peer_key = r_hash + '_' + peer_hdr['bgp_id'] + '_' + str(peer_hdr['dist_id'])

            if c_hash in self.COLLECTORS:
                msg.COLLECTOR_ADMIN_ID = self.COLLECTORS[c_hash]['admin_id']

            if r_hash in self.ROUTERS:
                msg.ROUTER_IP = self.ROUTERS[r_hash]['ip']
                msg.ROUTER_NAME = self.ROUTERS[r_hash]['name']

            if peer_key not in self.PEERS:
                self.PEERS[peer_key] = {'type': peer_hdr['type'],
                                        'flags': peer_hdr['flags'],
                                        'bgp_id': peer_hdr['bgp_id'],
                                        'peer_name': '',
                                        'remote_ip': '',
                                        'remote_asn': '',
                                        'local_ip': peer_hdr['addr'],
                                        'local_asn': peer_hdr['asn'],
                                        'router_hash': r_hash,
                                        'asn_len': 0,
                                        'rd': peer_hdr['dist_id']}
                if r_hash in self.ROUTERS:
                    if peer_key not in self.ROUTERS[r_hash]['peer-list']:
                        self.ROUTERS[r_hash]['peer-list'].append(peer_key)
                        
            current_peer = self.PEERS[peer_key]

            # Send to forward queue
            self.LOG.debug('Doing match for PEER KEY: {}'.format(peer_key))

            dest_peer_group = self.match_peer_group(current_peer)
            if dest_peer_group is not None:
                self.LOG.debug('PEER KEY: {} matched dest_peer_group {}'.format(peer_key, dest_peer_group['name']))
                msg.DEST_CONFIG_NAME = dest_peer_group['name']
                msg.DEST_COLLECTOR_HOST = dest_peer_group['collector']['host']
                msg.DEST_COLLECTOR_PORT = dest_peer_group['collector']['port']
                msg.BMP_MSG = data
                self._fwd_queue.put(msg)
            else:
                self.LOG.error('PEER KEY: {} did not match any dest_peer_group!'.format(peer_key))

    def match_peer_group(self, peer_dict):
        peer_groups = self._cfg['dest_peer_groups']
        try:
            for peer_exp in peer_groups:
                for regex in peer_exp['regexp_hostname']:
                    if re.match(regex, peer_dict['peer_name']) is not None:
                        return peer_exp
                for prefix in peer_exp['prefix_range']:
                    if peer_dict['local_ip'] in prefix.hosts():
                        return peer_exp
                if peer_dict['local_asn'] in peer_exp['asn']:
                    return peer_exp
            return None
        except Exception() as err:
            self.LOG.error('Something went wrong: {}'.format(err))
